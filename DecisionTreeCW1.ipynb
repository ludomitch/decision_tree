{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = np.loadtxt('noisy_dataset.txt')\n",
    "\n",
    "import math\n",
    "\n",
    "def entropy(labels):\n",
    "    size = labels.size\n",
    "    res = 0\n",
    "    for i in np.unique(labels):\n",
    "        pk = len(labels[labels==i])/size\n",
    "        res += pk * math.log(pk, 2)\n",
    "    return -res\n",
    "\n",
    "def remainder(s_left, s_right):\n",
    "    norm_const = lambda x,y: x.size/(x.size+y.size)\n",
    "    res = norm_const(s_left, s_right)*entropy(s_left)+norm_const(s_right, s_left)*entropy(s_right)\n",
    "    return res\n",
    "\n",
    "def info_gain(s_all, bound):\n",
    "    sorted_arr = s_all[s_all[:,0].argsort()]\n",
    "    s_left = sorted_arr[sorted_arr[:,0]>bound][:,1]\n",
    "    s_right = sorted_arr[sorted_arr[:,0]<bound][:,1]\n",
    "    sorted_arr = sorted_arr[:, 1]\n",
    "    return entropy(sorted_arr) - remainder(s_left, s_right)\n",
    "\n",
    "def get_boundaries(arr):\n",
    "    unique = np.unique(arr.copy())\n",
    "    x = unique[:-1]\n",
    "    y = unique[1:]\n",
    "    return (x+y)/2\n",
    "\n",
    "def find_split(data):\n",
    "    top_gain = 0\n",
    "    split = {}\n",
    "    for col in range(0, data.shape[1]-1): #don't include last col: label col\n",
    "        for boundary in get_boundaries(data[:, col]):\n",
    "            temp_gain = info_gain(data[:, [col,-1]], boundary)\n",
    "            if temp_gain > top_gain:\n",
    "                top_gain = temp_gain\n",
    "                split = {'attribute':col, 'value':boundary}\n",
    "    return split\n",
    "\n",
    "def split_data(arr, col, bound):\n",
    "    sorted_arr = arr[arr[:,col].argsort()]\n",
    "    left = arr[arr[:,col]>bound]\n",
    "    right = arr[arr[:,col]<bound]\n",
    "    return left, right\n",
    "\n",
    "def tree_learn(data, depth, tree):\n",
    "    max_depth = 4\n",
    "    if depth==max_depth:\n",
    "        return tree, depth\n",
    "    if np.all(data[:, -1]==data[0, -1]): # check if all labels are identical\n",
    "        return tree, depth\n",
    "    split = find_split(data)\n",
    "    split['left'] = {}\n",
    "    split['right'] = {}\n",
    "    tree = split\n",
    "    l_data, r_data = split_data(data, split['attribute'], split['value'])\n",
    "    l_branch, l_depth = tree_learn(l_data, depth+1, split['left'])\n",
    "    r_branch, r_depth = tree_learn(r_data, depth+1, split['right'])\n",
    "    tree['left'] = l_branch\n",
    "    tree['right'] = r_branch\n",
    "\n",
    "    return tree, max(l_depth, r_depth)\n",
    "\n",
    "def eval_tree(eval_data, tree):\n",
    "    \n",
    "    return error\n",
    "\n",
    "def score_tree(tree):\n",
    "    score = 1\n",
    "    return score\n",
    "\n",
    "def train_eval_test(data, folds=10, test_idx=0):\n",
    "    df = data.copy()\n",
    "    size = data.shape[0]\n",
    "    np.random.shuffle(df)\n",
    "    split_df = np.split(df, 10)\n",
    "    test = split_df[test_idx]\n",
    "    datasets = {}\n",
    "    for i in range(0:9):\n",
    "        datasets[i] = {'train':np.split(te,'eval'}\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     k_folds = {\n",
    "#         k:{'train':df[:size*(1-cut)], 'test':df[:size*cut], 'eval':df[:size*cut]} for k in range(0,10)\n",
    "#     }\n",
    "    return k_folds\n",
    "\n",
    "# res = tree_learn(data, 0, {})\n",
    "import pprint\n",
    "pprint.pprint(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('noisy_dataset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 8)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
